{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción\n",
    "En este notebook, realizaremos el preprocesamiento de datos utilizando NumPy. Aprenderemos cómo identificar y manejar valores faltantes, eliminar duplicados, detectar valores atípicos (outliers), y normalizar nuestros datos. El preprocesamiento es un paso crucial en la limpieza de datos antes de aplicar modelos de análisis o machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la librería NumPy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear Arreglo con Valores Faltantes\n",
    "Primero, crearemos un arreglo que contiene algunos valores faltantes. Estos valores faltantes serán identificados y reemplazados en los siguientes pasos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos con valores faltantes (NaN): [ 1.  2. nan  4.  5. nan  7.]\n"
     ]
    }
   ],
   "source": [
    "datos = np.array([1, 2, np.nan, 4, 5, np.nan, 7])\n",
    "\n",
    "print(\"Datos con valores faltantes (NaN):\", datos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificar Valores Faltantes\n",
    "Utilizamos la función `np.isnan()` para encontrar los valores faltantes (`NaN`). Esta función devuelve un arreglo booleano indicando qué elementos son `NaN`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en el arreglo: [False False  True False False  True False]\n"
     ]
    }
   ],
   "source": [
    "valores_faltantes = np.isnan(datos)\n",
    "print(\"Valores nulos en el arreglo:\", valores_faltantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reemplazar Valores Faltantes\n",
    "Una vez identificados los valores `NaN`, podemos reemplazarlos con la media de los valores no faltantes para mantener la coherencia del dataset.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8\n",
      "Datos con NaN reemplazados por la media: [1.  2.  3.8 4.  5.  3.8 7. ]\n"
     ]
    }
   ],
   "source": [
    "media = np.nanmean(datos) # Calcula la media sin considerar los NaN\n",
    "print(media )\n",
    "datos_reemplazados = np.where(np.isnan(datos), media, datos)\n",
    "print(\"Datos con NaN reemplazados por la media:\", datos_reemplazados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 0. 4. 5. 0. 7.]\n"
     ]
    }
   ],
   "source": [
    "datos_reemplazados_0=np.where(np.isnan(datos), 0, datos)\n",
    "print(datos_reemplazados_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "media_1=np.mean(datos)\n",
    "print(media_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar Valores Duplicados\n",
    "A continuación, creamos un nuevo arreglo con valores duplicados y utilizamos `np.unique()` para eliminar dichos duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos sin valores duplicados: [1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "datos_duplicados = np.array([1, 2, 2, 3, 4, 4, 5,5,6,6])\n",
    "datos_unicos = np.unique(datos_duplicados)\n",
    "print(\"Datos sin valores duplicados:\", datos_unicos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detectar Valores Atípicos (Outliers)\n",
    "Para identificar valores que se encuentren fuera de un rango aceptable, calculamos la media y la desviación estándar del conjunto de datos y consideramos como outliers aquellos valores que estén a más de 2 desviaciones estándar de la media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  2.  3.8 4.  5.  3.8 7. ]\n",
      "[]\n",
      "Valores atípicos (outliers): []\n"
     ]
    }
   ],
   "source": [
    "print(datos_reemplazados)\n",
    "\n",
    "media = np.mean(datos_reemplazados)\n",
    "desviacion = np.std(datos_reemplazados)\n",
    "umbral = 2\n",
    "outliers = datos_reemplazados[np.abs(datos_reemplazados - media) > umbral * desviacion]\n",
    "print(outliers)\n",
    "print(\"Valores atípicos (outliers):\", outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0e+00 2.0e+00 3.8e+00 4.0e+00 5.0e+00 3.8e+00 7.0e+00 2.5e+04 2.0e+00\n",
      " 3.0e+00 3.0e+00 2.0e+04 2.0e+00 3.0e+00 5.0e+00 6.0e+00 7.0e+00 1.0e+00\n",
      " 1.0e+00 1.0e+00 1.0e+00 1.0e+00 2.0e+00 2.0e+00]\n"
     ]
    }
   ],
   "source": [
    "datos_out=np.append(datos_reemplazados,[25000,2,3,3, 20000, 2,3,5,6,7,1,1,1,1,1,2,2,])\n",
    "print(datos_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25000. 20000.]\n"
     ]
    }
   ],
   "source": [
    "media = np.mean(datos_out)\n",
    "desviacion = np.std(datos_out)\n",
    "umbral = 2\n",
    "outliers = datos_out[np.abs(datos_out - media) > umbral * desviacion]\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  2.  3.  3.8 4.  5.  6.  7. ]\n"
     ]
    }
   ],
   "source": [
    "datos_w_o=np.setdiff1d(datos_out,outliers) #metodo incluye errores en esta version \n",
    "print(datos_w_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metodo mas exacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True False  True  True  True False\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "mask=~np.isin(datos_out,outliers)\n",
    "print(mask) #Todo: mascara donde los outlier aparecen como falsos entonces seran eliminados en sun aplicacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  2.  3.8 4.  5.  3.8 7.  2.  3.  3.  2.  3.  5.  6.  7.  1.  1.  1.\n",
      " 1.  1.  2.  2. ]\n"
     ]
    }
   ],
   "source": [
    "datos_w_o_better=datos_out[mask]\n",
    "print(datos_w_o_better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizar Datos\n",
    "Finalmente, normalizamos los datos para asegurarnos de que todos los valores se encuentren en un rango similar. Esto es útil para evitar que algunos valores con mayor magnitud dominen sobre otros durante el análisis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "7.0\n",
      "Datos normalizados: [0.         0.16666667 0.46666667 0.5        0.66666667 0.46666667\n",
      " 1.         0.16666667 0.33333333 0.33333333 0.16666667 0.33333333\n",
      " 0.66666667 0.83333333 1.         0.         0.         0.\n",
      " 0.         0.         0.16666667 0.16666667]\n"
     ]
    }
   ],
   "source": [
    "datos_min = np.min(datos_w_o_better)\n",
    "print(datos_min)\n",
    "datos_max = np.max(datos_w_o_better)\n",
    "print(datos_max)\n",
    "\n",
    "\n",
    "datos_normalizados = (datos_w_o_better - datos_min) / (datos_max - datos_min)\n",
    "print(\"Datos normalizados:\", datos_normalizados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar Valores Basados en una Condición\n",
    "Podemos filtrar los valores que cumplan con una condición específica, como aquellos que sean mayores a un determinado umbral. En este ejemplo, seleccionamos los valores mayores a 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores mayores a 4: [2.  3.8 4.  5.  3.8 7. ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "valores_mayores = datos_reemplazados[datos_reemplazados > 1]\n",
    "print(\"Valores mayores a 4:\", valores_mayores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "valores_cero=datos_normalizados[datos_normalizados==0]\n",
    "print(valores_cero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True False False False False False  True  True]\n",
      "[0.         0.16666667 0.46666667 0.5        0.66666667 0.46666667\n",
      " 1.         0.16666667 0.33333333 0.33333333 0.16666667 0.33333333\n",
      " 0.66666667 0.83333333 1.         0.         0.         0.\n",
      " 0.         0.         0.16666667 0.16666667]\n"
     ]
    }
   ],
   "source": [
    "mask=~np.isin(datos_normalizados,valores_cero)\n",
    "print(mask)\n",
    "print(datos_normalizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16666667 0.46666667 0.5        0.66666667 0.46666667 1.\n",
      " 0.16666667 0.33333333 0.33333333 0.16666667 0.33333333 0.66666667\n",
      " 0.83333333 1.         0.16666667 0.16666667]\n"
     ]
    }
   ],
   "source": [
    "datos_norm_sin_cero=datos_normalizados[mask]\n",
    "print(datos_norm_sin_cero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "El preprocesamiento de datos con NumPy incluye una serie de técnicas fundamentales que ayudan a mejorar la calidad de los datos para análisis posteriores. Estas incluyen la identificación y manejo de valores faltantes, la eliminación de duplicados, la detección de outliers y la normalización de datos. NumPy nos proporciona herramientas eficientes y rápidas para llevar a cabo estos procesos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leer un archivo CSV\n",
    "Podemos usar la función `np.genfromtxt()` para leer datos de un archivo CSV. Esta función es especialmente útil cuando los datos contienen valores faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos leídos del archivo CSV:\n",
      "[[nan nan 18. ...  5.  6.  6.]\n",
      " [nan nan 17. ...  5.  5.  6.]\n",
      " [nan nan 15. ...  7.  8. 10.]\n",
      " ...\n",
      " [nan nan 21. ... 10.  8.  7.]\n",
      " [nan nan 18. ... 11. 12. 10.]\n",
      " [nan nan 19. ...  8.  9.  9.]]\n"
     ]
    }
   ],
   "source": [
    "# Asegúrate de tener un archivo CSV llamado 'datos.csv' en el mismo directorio\n",
    "datos_csv = np.genfromtxt('student-mat.csv', delimiter=',', skip_header=1)\n",
    "print(\"Datos leídos del archivo CSV:\")\n",
    "print(datos_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0. 18. ...  5.  6.  6.]\n",
      " [ 0.  0. 17. ...  5.  5.  6.]\n",
      " [ 0.  0. 15. ...  7.  8. 10.]\n",
      " ...\n",
      " [ 0.  0. 21. ... 10.  8.  7.]\n",
      " [ 0.  0. 18. ... 11. 12. 10.]\n",
      " [ 0.  0. 19. ...  8.  9.  9.]]\n"
     ]
    }
   ],
   "source": [
    "datos_csv = np.where(np.isnan(datos_csv), 0, datos_csv)\n",
    "print(datos_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [2. 3.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [1. 3.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [2. 4.]\n",
      " [1. 3.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 3.]\n",
      " [2. 4.]\n",
      " [1. 1.]\n",
      " [1. 3.]\n",
      " [1. 2.]\n",
      " [2. 4.]\n",
      " [1. 1.]\n",
      " [5. 5.]\n",
      " [3. 4.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [2. 4.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [2. 2.]\n",
      " [1. 1.]\n",
      " [1. 4.]\n",
      " [1. 1.]\n",
      " [2. 2.]\n",
      " [1. 1.]\n",
      " [2. 3.]\n",
      " [1. 1.]\n",
      " [3. 4.]\n",
      " [2. 3.]\n",
      " [4. 4.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [2. 3.]\n",
      " [5. 5.]\n",
      " [1. 1.]\n",
      " [2. 4.]\n",
      " [2. 4.]\n",
      " [1. 2.]\n",
      " [5. 5.]\n",
      " [1. 2.]\n",
      " [1. 3.]\n",
      " [2. 3.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [2. 4.]\n",
      " [2. 2.]\n",
      " [2. 4.]\n",
      " [2. 3.]\n",
      " [1. 1.]\n",
      " [1. 3.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [1. 3.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [1. 3.]\n",
      " [2. 3.]\n",
      " [2. 3.]\n",
      " [1. 2.]\n",
      " [1. 3.]\n",
      " [1. 1.]\n",
      " [3. 5.]\n",
      " [1. 3.]\n",
      " [1. 3.]\n",
      " [2. 3.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [5. 5.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [3. 5.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 4.]\n",
      " [1. 2.]\n",
      " [1. 2.]\n",
      " [1. 2.]\n",
      " [1. 2.]\n",
      " [1. 4.]\n",
      " [1. 1.]\n",
      " [3. 2.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [2. 5.]\n",
      " [2. 2.]\n",
      " [1. 2.]\n",
      " [1. 3.]\n",
      " [1. 4.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [2. 4.]\n",
      " [1. 1.]\n",
      " [1. 3.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [2. 2.]\n",
      " [1. 1.]\n",
      " [3. 3.]\n",
      " [1. 2.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [2. 1.]\n",
      " [2. 5.]\n",
      " [2. 5.]\n",
      " [3. 5.]\n",
      " [2. 3.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [3. 3.]\n",
      " [1. 5.]\n",
      " [1. 2.]\n",
      " [4. 4.]\n",
      " [2. 2.]\n",
      " [1. 4.]\n",
      " [2. 4.]\n",
      " [1. 4.]\n",
      " [1. 5.]\n",
      " [1. 1.]\n",
      " [2. 4.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [2. 4.]\n",
      " [1. 1.]\n",
      " [1. 3.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [4. 4.]\n",
      " [1. 4.]\n",
      " [1. 4.]\n",
      " [3. 4.]\n",
      " [1. 1.]\n",
      " [2. 3.]\n",
      " [1. 2.]\n",
      " [2. 3.]\n",
      " [2. 3.]\n",
      " [1. 2.]\n",
      " [2. 3.]\n",
      " [1. 2.]\n",
      " [1. 2.]\n",
      " [1. 3.]\n",
      " [1. 5.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [4. 5.]\n",
      " [3. 4.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [3. 5.]\n",
      " [2. 3.]\n",
      " [1. 2.]\n",
      " [1. 5.]\n",
      " [1. 3.]\n",
      " [1. 3.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [3. 4.]\n",
      " [2. 2.]\n",
      " [1. 1.]\n",
      " [1. 4.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [4. 5.]\n",
      " [1. 1.]\n",
      " [2. 4.]\n",
      " [1. 2.]\n",
      " [1. 3.]\n",
      " [2. 4.]\n",
      " [2. 4.]\n",
      " [1. 4.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [5. 5.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 3.]\n",
      " [1. 3.]\n",
      " [4. 5.]\n",
      " [1. 2.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [1. 3.]\n",
      " [2. 4.]\n",
      " [1. 1.]\n",
      " [1. 3.]\n",
      " [5. 5.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [3. 5.]\n",
      " [1. 4.]\n",
      " [2. 3.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [5. 5.]\n",
      " [1. 3.]\n",
      " [2. 4.]\n",
      " [2. 4.]\n",
      " [1. 3.]\n",
      " [2. 5.]\n",
      " [1. 3.]\n",
      " [2. 4.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [1. 3.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [3. 4.]\n",
      " [3. 4.]\n",
      " [2. 2.]\n",
      " [1. 3.]\n",
      " [1. 2.]\n",
      " [3. 3.]\n",
      " [1. 3.]\n",
      " [1. 1.]\n",
      " [2. 2.]\n",
      " [1. 1.]\n",
      " [2. 3.]\n",
      " [1. 1.]\n",
      " [1. 4.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [2. 4.]\n",
      " [3. 4.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [1. 2.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [1. 3.]\n",
      " [1. 1.]\n",
      " [1. 4.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 3.]\n",
      " [2. 3.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [2. 2.]\n",
      " [1. 1.]\n",
      " [2. 2.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [1. 3.]\n",
      " [2. 2.]\n",
      " [1. 1.]\n",
      " [2. 2.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [2. 5.]\n",
      " [3. 3.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [2. 2.]\n",
      " [2. 3.]\n",
      " [2. 3.]\n",
      " [2. 2.]\n",
      " [3. 5.]\n",
      " [5. 5.]\n",
      " [1. 3.]\n",
      " [1. 2.]\n",
      " [2. 4.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 3.]\n",
      " [1. 2.]\n",
      " [2. 3.]\n",
      " [1. 1.]\n",
      " [2. 3.]\n",
      " [1. 3.]\n",
      " [2. 2.]\n",
      " [1. 3.]\n",
      " [1. 2.]\n",
      " [1. 2.]\n",
      " [2. 3.]\n",
      " [1. 2.]\n",
      " [2. 3.]\n",
      " [1. 3.]\n",
      " [5. 5.]\n",
      " [3. 3.]\n",
      " [2. 3.]\n",
      " [2. 3.]\n",
      " [3. 3.]\n",
      " [1. 3.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [1. 2.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [1. 4.]\n",
      " [2. 3.]\n",
      " [1. 3.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [2. 4.]\n",
      " [2. 2.]\n",
      " [1. 2.]\n",
      " [1. 2.]\n",
      " [4. 2.]\n",
      " [1. 1.]\n",
      " [2. 3.]\n",
      " [1. 1.]\n",
      " [1. 3.]\n",
      " [1. 1.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [3. 4.]\n",
      " [1. 2.]\n",
      " [2. 3.]\n",
      " [1. 4.]\n",
      " [1. 3.]\n",
      " [1. 1.]\n",
      " [1. 3.]\n",
      " [4. 3.]\n",
      " [1. 3.]\n",
      " [2. 2.]\n",
      " [1. 2.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [4. 5.]\n",
      " [3. 4.]\n",
      " [3. 3.]\n",
      " [3. 4.]\n",
      " [3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "datos_imp=datos_csv[:,-7:-5]\n",
    "\n",
    "print(datos_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 33)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(datos_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 2)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(datos_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.48101266 2.29113924]\n"
     ]
    }
   ],
   "source": [
    "average=np.mean(datos_imp,axis=0)\n",
    "print(average)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio de consumo de alcohol en fines de semana: 2.2911392405063293\n",
      "Promedio de consumo de alcohol en dias entresemana: 1.481012658227848\n"
     ]
    }
   ],
   "source": [
    "print(f\"Promedio de consumo de alcohol en fines de semana: {average[1]}\")\n",
    "\n",
    "print(f\"Promedio de consumo de alcohol en dias entresemana: {average[0]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88961319 1.28626531]\n"
     ]
    }
   ],
   "source": [
    "std_desv=np.std(datos_imp, axis=0)\n",
    "print(std_desv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desviación estandar de consumo de alcohol en fines de semana: 0.8896131927704085\n",
      "Desviación estandar de consumo de alcohol en dias entresemana: 1.286265310488668\n"
     ]
    }
   ],
   "source": [
    "print(f\"Desviación estandar de consumo de alcohol en fines de semana: {std_desv[1]}\")\n",
    "\n",
    "print(f\"Desviación estandar de consumo de alcohol en dias entresemana: {std_desv[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "program_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
